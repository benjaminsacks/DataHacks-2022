{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from collections import defaultdict\n",
    "import regex as re\n",
    "# nlp libraries\n",
    "import string\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$SPY wouldn't be surprised to see a green close</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shell's $70 Billion BG Deal Meets Shareholder ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SSH COMMUNICATIONS SECURITY CORP STOCK EXCHANG...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment\n",
       "0  According to the Finnish-Russian Chamber of Co...   neutral\n",
       "1  The Swedish buyout firm has sold its remaining...   neutral\n",
       "2    $SPY wouldn't be surprised to see a green close  positive\n",
       "3  Shell's $70 Billion BG Deal Meets Shareholder ...  negative\n",
       "4  SSH COMMUNICATIONS SECURITY CORP STOCK EXCHANG...  negative"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_df = pd.read_csv('advanced_trainset.csv')\n",
    "dirty_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A collection of texts is also sometimes called \"corpus\". Let's print the first ten messages and number them using **enumerate**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    According to the Finnish-Russian Chamber of Co...\n",
       "1    The Swedish buyout firm has sold its remaining...\n",
       "2      $SPY wouldn't be surprised to see a green close\n",
       "3    Shell's $70 Billion BG Deal Meets Shareholder ...\n",
       "4    SSH COMMUNICATIONS SECURITY CORP STOCK EXCHANG...\n",
       "5    The Stockmann department store will have a tot...\n",
       "6    Circulation revenue has increased by 5 % in Fi...\n",
       "7    $SAP Q1 disappoints as #software licenses down...\n",
       "8    The subdivision made sales revenues last year ...\n",
       "9             Viking Line has canceled some services .\n",
       "Name: Sentence, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_df.Sentence[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 According to the Finnish-Russian Chamber of Commerce , all the major construction companies of Finland are operating in Russia .\n",
      "\n",
      "\n",
      "1 The Swedish buyout firm has sold its remaining 22.4 percent stake , almost eighteen months after taking the company public in Finland .\n",
      "\n",
      "\n",
      "2 $SPY wouldn't be surprised to see a green close\n",
      "\n",
      "\n",
      "3 Shell's $70 Billion BG Deal Meets Shareholder Skepticism\n",
      "\n",
      "\n",
      "4 SSH COMMUNICATIONS SECURITY CORP STOCK EXCHANGE RELEASE OCTOBER 14 , 2008 AT 2:45 PM The Company updates its full year outlook and estimates its results to remain at loss for the full year .\n",
      "\n",
      "\n",
      "5 The Stockmann department store will have a total floor space of over 8,000 square metres and Stockmann 's investment in the project will have a price tag of about EUR 12 million .\n",
      "\n",
      "\n",
      "6 Circulation revenue has increased by 5 % in Finland and 4 % in Sweden in 2008 .\n",
      "\n",
      "\n",
      "7 $SAP Q1 disappoints as #software licenses down. Real problem? #Cloud growth trails $MSFT $ORCL $GOOG $CRM $ADBE https://t.co/jNDphllzq5\n",
      "\n",
      "\n",
      "8 The subdivision made sales revenues last year of EUR 480.7 million EUR 414.9 million in 2008 , and operating profits of EUR 44.5 million EUR 7.4 million .\n",
      "\n",
      "\n",
      "9 Viking Line has canceled some services .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for message_no, message in enumerate(dirty_df.Sentence[:10]):\n",
    "    print(message_no, message)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use **read_csv** and make note of the **sep** argument, we can also specify the desired column names by passing in a list of *names*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Let's check out some of the stats with some plots and the built-in methods in pandas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4382</td>\n",
       "      <td>4382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>4081</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>In the first half of 2008 , the Bank 's operat...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>2363</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Sentence Sentiment\n",
       "count                                                4382      4382\n",
       "unique                                               4081         3\n",
       "top     In the first half of 2008 , the Bank 's operat...   neutral\n",
       "freq                                                    2      2363"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use **groupby** to use describe by label, this way we can begin to think about the features that separate ham and spam!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Sentence</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentiment</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>636</td>\n",
       "      <td>636</td>\n",
       "      <td>Shell's $70 Billion BG Deal Meets Shareholder ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neutral</th>\n",
       "      <td>2363</td>\n",
       "      <td>2360</td>\n",
       "      <td>The company serves customers in various indust...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>1383</td>\n",
       "      <td>1383</td>\n",
       "      <td>$SPY wouldn't be surprised to see a green close</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sentence                                                            \\\n",
       "             count unique                                                top   \n",
       "Sentiment                                                                      \n",
       "negative       636    636  Shell's $70 Billion BG Deal Meets Shareholder ...   \n",
       "neutral       2363   2360  The company serves customers in various indust...   \n",
       "positive      1383   1383    $SPY wouldn't be surprised to see a green close   \n",
       "\n",
       "                \n",
       "          freq  \n",
       "Sentiment       \n",
       "negative     1  \n",
       "neutral      2  \n",
       "positive     1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_df.groupby('Sentiment').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how long the text messages are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirty_df.to_csv('new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$SPY wouldn't be surprised to see a green close</td>\n",
       "      <td>positive</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shell's $70 Billion BG Deal Meets Shareholder ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SSH COMMUNICATIONS SECURITY CORP STOCK EXCHANG...</td>\n",
       "      <td>negative</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence Sentiment  length\n",
       "0  According to the Finnish-Russian Chamber of Co...   neutral     128\n",
       "1  The Swedish buyout firm has sold its remaining...   neutral     135\n",
       "2    $SPY wouldn't be surprised to see a green close  positive      47\n",
       "3  Shell's $70 Billion BG Deal Meets Shareholder ...  negative      56\n",
       "4  SSH COMMUNICATIONS SECURITY CORP STOCK EXCHANG...  negative     190"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_df['length'] = dirty_df['Sentence'].apply(len)\n",
    "dirty_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     2363\n",
       "positive    1383\n",
       "negative     636\n",
       "Name: Sentiment, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_df.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**There seems to be an imbalance in the dataset with small negative counts**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Frequency'>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dirty_df['length'].plot(bins=50, kind='hist') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shortest message only contains up to quite a bit more than 300 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4382.000000\n",
       "mean      117.269968\n",
       "std        56.811408\n",
       "min         9.000000\n",
       "25%        72.000000\n",
       "50%       107.000000\n",
       "75%       151.000000\n",
       "max       315.000000\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dirty_df.length.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Supported Nokia phones include : N96 , N95-8GB , N95 , N93-N931 , N92 , N85 , N82 , N81 , N80 , N79 , N78 , N77 , N76 , N75 , N73 , N72 , N71 , E90 , E71 , E70 , E66 , E65 , E62 , E61-E61i , E60 , E51 , E50 , Touch Xpress 5800 , 6220 Classic , 6210 Navigator , 6120 Classic , 6110 Navigator , 5700 , 5500 , 5320XM .'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See what's in the longest message\n",
    "dirty_df[dirty_df['length'] == dirty_df.describe().loc['max'].values[0]]['Sentence'].iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See how those sentences with their sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dirty_df.Sentiment.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot:title={'center':'negative'}>,\n",
       "        <AxesSubplot:title={'center':'neutral'}>],\n",
       "       [<AxesSubplot:title={'center':'positive'}>, <AxesSubplot:>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dirty_df.hist(column='length', by='Sentiment', bins=50,figsize=(12,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything follows a common trend: peaks around 50-100\n",
    "\n",
    "neutral is unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>Sentence_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>128</td>\n",
       "      <td>according to the finnish-russian chamber of co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>135</td>\n",
       "      <td>the swedish buyout firm has sold its remaining...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$SPY wouldn't be surprised to see a green close</td>\n",
       "      <td>positive</td>\n",
       "      <td>47</td>\n",
       "      <td>$spy wouldn't be surprised to see a green close</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Shell's $70 Billion BG Deal Meets Shareholder ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>56</td>\n",
       "      <td>shell's $70 billion bg deal meets shareholder ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SSH COMMUNICATIONS SECURITY CORP STOCK EXCHANG...</td>\n",
       "      <td>negative</td>\n",
       "      <td>190</td>\n",
       "      <td>ssh communications security corp stock exchang...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4377</th>\n",
       "      <td>Investments in product development stood at 6....</td>\n",
       "      <td>neutral</td>\n",
       "      <td>72</td>\n",
       "      <td>investments in product development stood at 6....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4378</th>\n",
       "      <td>HSBC Says Unit to Book $585 Million Charge on ...</td>\n",
       "      <td>negative</td>\n",
       "      <td>56</td>\n",
       "      <td>hsbc says unit to book $585 million charge on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4379</th>\n",
       "      <td>RISING costs have forced packaging producer Hu...</td>\n",
       "      <td>negative</td>\n",
       "      <td>107</td>\n",
       "      <td>rising costs have forced packaging producer hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>In the building and home improvement trade , s...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>88</td>\n",
       "      <td>in the building and home improvement trade , s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>HELSINKI AFX - KCI Konecranes said it has won ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>145</td>\n",
       "      <td>helsinki afx - kci konecranes said it has won ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4382 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence Sentiment  length  \\\n",
       "0     According to the Finnish-Russian Chamber of Co...   neutral     128   \n",
       "1     The Swedish buyout firm has sold its remaining...   neutral     135   \n",
       "2       $SPY wouldn't be surprised to see a green close  positive      47   \n",
       "3     Shell's $70 Billion BG Deal Meets Shareholder ...  negative      56   \n",
       "4     SSH COMMUNICATIONS SECURITY CORP STOCK EXCHANG...  negative     190   \n",
       "...                                                 ...       ...     ...   \n",
       "4377  Investments in product development stood at 6....   neutral      72   \n",
       "4378  HSBC Says Unit to Book $585 Million Charge on ...  negative      56   \n",
       "4379  RISING costs have forced packaging producer Hu...  negative     107   \n",
       "4380  In the building and home improvement trade , s...   neutral      88   \n",
       "4381  HELSINKI AFX - KCI Konecranes said it has won ...  positive     145   \n",
       "\n",
       "                                       Sentence_cleaned  \n",
       "0     according to the finnish-russian chamber of co...  \n",
       "1     the swedish buyout firm has sold its remaining...  \n",
       "2       $spy wouldn't be surprised to see a green close  \n",
       "3     shell's $70 billion bg deal meets shareholder ...  \n",
       "4     ssh communications security corp stock exchang...  \n",
       "...                                                 ...  \n",
       "4377  investments in product development stood at 6....  \n",
       "4378  hsbc says unit to book $585 million charge on ...  \n",
       "4379  rising costs have forced packaging producer hu...  \n",
       "4380  in the building and home improvement trade , s...  \n",
       "4381  helsinki afx - kci konecranes said it has won ...  \n",
       "\n",
       "[4382 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned = dirty_df.copy(deep=True)\n",
    "cleaned[\"Sentence_cleaned\"] = cleaned[\"Sentence\"].str.lower()\n",
    "# cleaned[\"Sentence_cleaned\"] = cleaned[\"Sentence_cleaned\"].str.replace(r\",|\\.\", \" \")\n",
    "cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = defaultdict(int) # counting appearance of each word\n",
    "for i in cleaned[\"Sentence_cleaned\"]:\n",
    "    for i in i.split():\n",
    "        words[i] += 1\n",
    "        \n",
    "word_index = {} # find index of a word for feature engineering\n",
    "counter = 0\n",
    "for i in words:\n",
    "    if words[i] > 1:\n",
    "        word_index[i] = counter\n",
    "        counter += 1\n",
    "word_index[\" \"] = counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = [] # add number of appereances of the word based on the index\n",
    "for sentence in cleaned[\"Sentence_cleaned\"]:\n",
    "    result = [0] * 5225 # total number of unique words that appear more than once\n",
    "    for word in sentence.split(\" \"):\n",
    "        if word in word_index:\n",
    "            result[word_index[word]] += 1\n",
    "    word_count.append(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5216</th>\n",
       "      <th>5217</th>\n",
       "      <th>5218</th>\n",
       "      <th>5219</th>\n",
       "      <th>5220</th>\n",
       "      <th>5221</th>\n",
       "      <th>5222</th>\n",
       "      <th>5223</th>\n",
       "      <th>5224</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...  5216  5217  5218  5219  5220  5221  \\\n",
       "0  1  1  2  2  1  1  1  1  1  1  ...     0     0     0     0     0     0   \n",
       "1  0  0  2  0  0  1  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "2  0  1  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "3  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "4  0  1  2  0  0  1  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "\n",
       "   5222  5223  5224  length  \n",
       "0     0     0     0      20  \n",
       "1     0     0     0      23  \n",
       "2     0     0     0       9  \n",
       "3     0     0     0       8  \n",
       "4     0     0     0      34  \n",
       "\n",
       "[5 rows x 5226 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(word_count)\n",
    "df[\"length\"] = cleaned[\"Sentence_cleaned\"].str.split().apply(len) # length as additional feature\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model testing\n",
    "We are trying out a few different classifers: Decision Tree, Random Forest & Ada Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train & test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(df,cleaned[\"Sentiment\"],test_size=0.25,random_state=69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.32      0.38      0.35       159\n",
      "     neutral       0.75      0.72      0.74       604\n",
      "    positive       0.67      0.66      0.67       333\n",
      "\n",
      "    accuracy                           0.65      1096\n",
      "   macro avg       0.58      0.59      0.58      1096\n",
      "weighted avg       0.66      0.65      0.66      1096\n",
      "\n",
      "Accuracy:0.6523722627737226\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "predictions =list(clf.predict(X_test)) \n",
    "print(classification_report(y_test, predictions))\n",
    "# classification_report(y_test, predictions,output_dict=True)['accuracy']\n",
    "acc = classification_report(y_test, predictions,output_dict=True)['accuracy']\n",
    "f1_score = ''\n",
    "print(f'Accuracy:{acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.26      0.16      0.20       159\n",
      "     neutral       0.72      0.85      0.78       604\n",
      "    positive       0.73      0.62      0.67       333\n",
      "\n",
      "    accuracy                           0.68      1096\n",
      "   macro avg       0.57      0.54      0.55      1096\n",
      "weighted avg       0.66      0.68      0.66      1096\n",
      "\n",
      "Accuracy:0.6806569343065694\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "predictions =list(clf.predict(X_test)) \n",
    "print(classification_report(y_test, predictions))\n",
    "# classification_report(y_test, predictions,output_dict=True)['accuracy']\n",
    "acc = classification_report(y_test, predictions,output_dict=True)['accuracy']\n",
    "print(f'Accuracy:{acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.47      0.22      0.30       159\n",
      "     neutral       0.74      0.89      0.80       604\n",
      "    positive       0.71      0.62      0.66       333\n",
      "\n",
      "    accuracy                           0.71      1096\n",
      "   macro avg       0.64      0.58      0.59      1096\n",
      "weighted avg       0.69      0.71      0.69      1096\n",
      "\n",
      "Accuracy: 0.7098540145985401\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "predictions =list(clf.predict(X_test)) \n",
    "print(classification_report(y_test, predictions))\n",
    "# classification_report(y_test, predictions,output_dict=True)['accuracy']\n",
    "acc = classification_report(y_test, predictions,output_dict=True)['accuracy']\n",
    "print(f'Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on models we have, Ada Boost Classifer has the best accuracy score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We proceed to a new method by removing punctuation and also use tf-idf model to put into our pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Messs Hello Dollar sign 70 with other punctuations'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "mess = 'Messs! Hello: Dollar sign $70 with other punctuations.'\n",
    "\n",
    "# Check characters to see if they are in punctuation\n",
    "nopunc = [char for char in mess if char not in string.punctuation]\n",
    "#  or '$' in char\n",
    "\n",
    "# Join the characters again to form the string.\n",
    "nopunc = ''.join(nopunc)\n",
    "nopunc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how to remove stopwords. We can impot a list of english stopwords from NLTK (check the documentation for more languages and info)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['messs', 'hello', 'dollar', 'sign', '70', 'with', 'other', 'punctuations']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove any stopwords & make it lowercase\n",
    "clean_mess = [word.lower() for word in nopunc.split() if word.lower() not in stopwords]\n",
    "# or '$' in word.lower()\n",
    "clean_mess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's put both of these together in a function to apply it to our DataFrame later on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_sentence(s):\n",
    "    '''\n",
    "    Remove selective puntuations & other sentence junk\n",
    "    '''\n",
    "    # To lowercase\n",
    "    s = s.lower()\n",
    "\n",
    "    # Remove apostrophes\n",
    "    s = re.sub(' \\'s', '', s)\n",
    "\n",
    "    # Fix % and $ whitespace\n",
    "    s = re.sub('(?<=\\d) %', '%', s)\n",
    "    s = re.sub('\\$ (?=\\d)', '$', s)\n",
    "\n",
    "    # Remove links\n",
    "    s = re.sub('http\\S+', ' ', s)\n",
    "\n",
    "    # Remove .'s not surrounded by numbers\n",
    "    s = re.sub('(?<!\\d)\\.|\\,(?!\\d)', ' ', s)\n",
    "\n",
    "    # Remove punctuation\n",
    "    s = re.sub('-|\\(|\\)', ' ', s)\n",
    "    s = re.sub('\\'|\\,|\\`', '', s)\n",
    "\n",
    "    # Remove extra whitespace\n",
    "    s = re.sub(' +', ' ', s)\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    according to the finnish russian chamber of co...\n",
       "1    the swedish buyout firm has sold its remaining...\n",
       "2       $spy wouldnt be surprised to see a green close\n",
       "3    shells $70 billion bg deal meets shareholder s...\n",
       "4    ssh communications security corp stock exchang...\n",
       "Name: Sentence, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to make sure its working\n",
    "dirty_df['Sentence'].head(5).apply(clean_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [According, to, the, FinnishRussian, Chamber, ...\n",
       "1    [The, Swedish, buyout, firm, has, sold, its, r...\n",
       "2    [SPY, wouldnt, be, surprised, to, see, a, gree...\n",
       "3    [Shells, 70, Billion, BG, Deal, Meets, Shareho...\n",
       "4    [SSH, COMMUNICATIONS, SECURITY, CORP, STOCK, E...\n",
       "Name: Sentence, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check to make sure its working\n",
    "dirty_df['Sentence'].head(5).apply(text_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "Tokenization is just the term used to describe the process of converting the normal text strings in to a list of tokens (words that we actually want).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Continuing Normalization\n",
    "\n",
    "There are a lot of ways to continue normalizing this text. Such as [Stemming](https://en.wikipedia.org/wiki/Stemming) or distinguishing by [part of speech](http://www.nltk.org/book/ch05.html).\n",
    "\n",
    "NLTK has lots of built-in tools and great documentation on a lot of these methods. Sometimes they don't work well for text-messages due to the way a lot of people tend to use abbreviations or shorthand, For example:\n",
    "    \n",
    "    'Nah dawg, IDK! Wut time u headin to da club?'\n",
    "    \n",
    "versus\n",
    "\n",
    "    'No dog, I don't know! What time are you heading to the club?'\n",
    "    \n",
    "Some text normalization methods will have trouble with this type of shorthand and so I'll leave you to explore those more advanced methods through the [NLTK book online](http://www.nltk.org/book/).\n",
    "\n",
    "For now we will just focus on using what we have to convert our list of words to an actual vector that SciKit-Learn can use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, we have the messages as lists of tokens (also known as [lemmas](http://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html)) and now we need to convert each of those messages into a vector the SciKit Learn's algorithm models can work with.\n",
    "\n",
    "Now we'll convert each message, represented as a list of tokens (lemmas) above, into a vector that machine learning models can understand.\n",
    "\n",
    "We'll do that in three steps using the bag-of-words model:\n",
    "\n",
    "1. Count how many times does a word occur in each message (Known as term frequency)\n",
    "\n",
    "2. Weigh the counts, so that frequent tokens get lower weight (inverse document frequency)\n",
    "\n",
    "3. Normalize the vectors to unit length, to abstract from the original text length (L2 norm)\n",
    "\n",
    "Let's begin the first step:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each vector will have as many dimensions as there are unique words in the SMS corpus.  We will first use SciKit Learn's **CountVectorizer**. This model will convert a collection of text documents to a matrix of token counts.\n",
    "\n",
    "We can imagine this as a 2-Dimensional matrix. Where the 1-dimension is the entire vocabulary (1 row per word) and the other dimension are the actual documents, in this case a column per text message. \n",
    "\n",
    "For example:\n",
    "\n",
    "<table border = “1“>\n",
    "<tr>\n",
    "<th></th> <th>Message 1</th> <th>Message 2</th> <th>...</th> <th>Message N</th> \n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Word 1 Count</b></td><td>0</td><td>1</td><td>...</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Word 2 Count</b></td><td>0</td><td>0</td><td>...</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>...</b></td> <td>1</td><td>2</td><td>...</td><td>0</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td><b>Word N Count</b></td> <td>0</td><td>1</td><td>...</td><td>1</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "Since there are so many messages, we can expect a lot of zero counts for the presence of that word in that document. Because of this, SciKit Learn will output a [Sparse Matrix](https://en.wikipedia.org/wiki/Sparse_matrix)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of arguments and parameters that can be passed to the CountVectorizer. In this case we will just specify the **analyzer** to be our own previously defined function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12300\n"
     ]
    }
   ],
   "source": [
    "# Take a while\n",
    "bow_transformer = CountVectorizer(analyzer=text_process).fit(dirty_df['Sentence'])\n",
    "\n",
    "# Show total number of vocab words\n",
    "print(len(bow_transformer.vocabulary_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take one text message and get its bag-of-words counts as a vector, putting to use our new `bow_transformer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shell's $70 Billion BG Deal Meets Shareholder Skepticism\n"
     ]
    }
   ],
   "source": [
    "message4 = dirty_df['Sentence'][3]\n",
    "print(message4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see its vector representation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 1194)\t1\n",
      "  (0, 1764)\t1\n",
      "  (0, 1892)\t1\n",
      "  (0, 2440)\t1\n",
      "  (0, 4215)\t1\n",
      "  (0, 5488)\t1\n",
      "  (0, 5495)\t1\n",
      "  (0, 5550)\t1\n",
      "(1, 12300)\n"
     ]
    }
   ],
   "source": [
    "bow4 = bow_transformer.transform([message4])\n",
    "print(bow4)\n",
    "print(bow4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "004\n",
      "043\n"
     ]
    }
   ],
   "source": [
    "print(bow_transformer.get_feature_names()[10])\n",
    "print(bow_transformer.get_feature_names()[50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use **.transform** on our Bag-of-Words (bow) transformed object and transform the entire DataFrame of messages. Let's go ahead and check out how the bag-of-words counts for the entire SMS corpus is a large, sparse matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages_bow = bow_transformer.transform(dirty_df['Sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of Sparse Matrix:  (4382, 12300)\n",
      "Amount of Non-Zero occurences:  75188\n"
     ]
    }
   ],
   "source": [
    "print('Shape of Sparse Matrix: ', messages_bow.shape)\n",
    "print('Amount of Non-Zero occurences: ', messages_bow.nnz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0\n"
     ]
    }
   ],
   "source": [
    "sparsity = (100.0 * messages_bow.nnz / (messages_bow.shape[0] * messages_bow.shape[1]))\n",
    "print('sparsity: {}'.format(round(sparsity)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the counting, the term weighting and normalization can be done with [TF-IDF](http://en.wikipedia.org/wiki/Tf%E2%80%93idf), using scikit-learn's `TfidfTransformer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 5550)\t0.39629165715027104\n",
      "  (0, 5495)\t0.3778061386922472\n",
      "  (0, 5488)\t0.3778061386922472\n",
      "  (0, 4215)\t0.39629165715027104\n",
      "  (0, 2440)\t0.31460373363129207\n",
      "  (0, 1892)\t0.33308925208931595\n",
      "  (0, 1764)\t0.32291593716252964\n",
      "  (0, 1194)\t0.29365324199362997\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer().fit(messages_bow)\n",
    "tfidf4 = tfidf_transformer.transform(bow4)\n",
    "print(tfidf4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll go ahead and check what is the IDF (inverse document frequency) of the word `\"u\"`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.692341519858864\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_transformer.idf_[bow_transformer.vocabulary_['u']])\n",
    "# print(tfidf_transformer.idf_[bow_transformer.vocabulary_['']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To transform the entire bag-of-words corpus into TF-IDF corpus at once:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4382, 12300)\n"
     ]
    }
   ],
   "source": [
    "messages_tfidf = tfidf_transformer.transform(messages_bow)\n",
    "print(messages_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With messages represented as vectors, we can finally train our classifier. Now we can actually use almost any sort of classification algorithms. For a [variety of reasons](http://www.inf.ed.ac.uk/teaching/courses/inf2b/learnnotes/inf2b-learn-note07-2up.pdf), the Naive Bayes classifier algorithm is a good choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using scikit-learn here, choosing the [Naive Bayes](http://en.wikipedia.org/wiki/Naive_Bayes_classifier) classifier to start with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "spam_detect_model = MultinomialNB().fit(messages_tfidf, dirty_df['Sentiment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try classifying our single random message and checking how we do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted: positive\n",
      "expected: negative\n"
     ]
    }
   ],
   "source": [
    "print('predicted:', spam_detect_model.predict(tfidf4)[0])\n",
    "print('expected:', dirty_df.Sentiment[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation\n",
    "Now we want to determine how well our model will do overall on the entire dataset. Let's begin by getting all the predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['neutral' 'neutral' 'positive' ... 'neutral' 'neutral' 'positive']\n"
     ]
    }
   ],
   "source": [
    "all_predictions = spam_detect_model.predict(messages_tfidf)\n",
    "print(all_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use SciKit Learn's built-in classification report, which returns [precision, recall,](https://en.wikipedia.org/wiki/Precision_and_recall) [f1-score](https://en.wikipedia.org/wiki/F1_score), and a column for support (meaning how many cases supported that classification). Check out the links for more detailed info on each of these metrics and the figure below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/Precisionrecall.svg/700px-Precisionrecall.svg.png' width=400 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.14      0.25       636\n",
      "     neutral       0.69      1.00      0.81      2363\n",
      "    positive       0.91      0.57      0.70      1383\n",
      "\n",
      "    accuracy                           0.74      4382\n",
      "   macro avg       0.87      0.57      0.59      4382\n",
      "weighted avg       0.80      0.74      0.70      4382\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print (classification_report(dirty_df['Sentiment'], all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7380191693290735"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(dirty_df['Sentiment'], all_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3505 877 4382\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "msg_train, msg_test, label_train, label_test = \\\n",
    "train_test_split(dirty_df['Sentence'], dirty_df['Sentiment'], test_size=0.2)\n",
    "\n",
    "print(len(msg_train), len(msg_test), len(msg_train) + len(msg_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test size is 20% of the entire dataset, and the training is the rest. Note the default split would have been 30/70.\n",
    "\n",
    "## Creating a Data Pipeline\n",
    "\n",
    "Let's run our model again and then predict off the test set. We will use SciKit Learn's [pipeline](http://scikit-learn.org/stable/modules/pipeline.html) capabilities to store a pipeline of workflow. This will allow us to set up all the transformations that we will do to the data for future use. Let's see an example of how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "# from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_naive_bayes = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "#     ('decision_tree',  DecisionTreeClassifier(random_state=0)),\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_tree = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('decision_tree',  DecisionTreeClassifier(random_state=0)),\n",
    "#     ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_adaboost = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('ada_boost',  AdaBoostClassifier()),\n",
    "#     ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can directly pass message text data and the pipeline will do our pre-processing for us! We can treat it as a model/estimator API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bow',\n",
       "                 CountVectorizer(analyzer=<function text_process at 0x7fd778decd30>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('ada_boost', AdaBoostClassifier())])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_naive_bayes.fit(msg_train,label_train)\n",
    "pipeline_tree.fit(msg_train,label_train)\n",
    "pipeline_adaboost.fit(msg_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_naive_bayes = pipeline_naive_bayes.predict(msg_test)\n",
    "predictions_tree = pipeline_tree.predict(msg_test)\n",
    "predictions_adaboost = pipeline_adaboost.predict(msg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_df = df.copy()\n",
    "# new_df['pred_nb'] = predictions_naive_bayes\n",
    "# new_df['pred_tree'] = predictions_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.22      0.23      0.23       128\n",
      "     neutral       0.67      0.63      0.65       497\n",
      "    positive       0.53      0.58      0.55       252\n",
      "\n",
      "    accuracy                           0.56       877\n",
      "   macro avg       0.47      0.48      0.48       877\n",
      "weighted avg       0.56      0.56      0.56       877\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.556442417331813"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tree\n",
    "print(classification_report(predictions_tree,label_test))\n",
    "accuracy_score(label_test, predictions_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.04      1.00      0.09         6\n",
      "     neutral       0.97      0.60      0.74       760\n",
      "    positive       0.28      0.70      0.40       111\n",
      "\n",
      "    accuracy                           0.61       877\n",
      "   macro avg       0.43      0.77      0.41       877\n",
      "weighted avg       0.88      0.61      0.69       877\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6123147092360319"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "print(classification_report(predictions_naive_bayes,label_test))\n",
    "accuracy_score(label_test, predictions_naive_bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.31      0.55      0.40        76\n",
      "     neutral       0.81      0.70      0.75       538\n",
      "    positive       0.59      0.62      0.60       263\n",
      "\n",
      "    accuracy                           0.66       877\n",
      "   macro avg       0.57      0.62      0.58       877\n",
      "weighted avg       0.70      0.66      0.68       877\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6624857468643102"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ada_boost\n",
    "print(classification_report(predictions_adaboost,label_test))\n",
    "accuracy_score(label_test, predictions_adaboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ben functions classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_naive_bayes = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=clean_sentence)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "#     ('decision_tree',  DecisionTreeClassifier(random_state=0)),\n",
    "    ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "pipeline_tree = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('decision_tree',  DecisionTreeClassifier(random_state=0)),\n",
    "#     ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])\n",
    "pipeline_adaboost = Pipeline([\n",
    "    ('bow', CountVectorizer(analyzer=text_process)),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('ada_boost',  AdaBoostClassifier()),\n",
    "#     ('classifier', MultinomialNB()),  # train on TF-IDF vectors w/ Naive Bayes classifier\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('bow',\n",
       "                 CountVectorizer(analyzer=<function text_process at 0x7fd778decd30>)),\n",
       "                ('tfidf', TfidfTransformer()),\n",
       "                ('ada_boost', AdaBoostClassifier())])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_naive_bayes.fit(msg_train,label_train)\n",
    "pipeline_tree.fit(msg_train,label_train)\n",
    "pipeline_adaboost.fit(msg_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_naive_bayes = pipeline_naive_bayes.predict(msg_test)\n",
    "predictions_tree = pipeline_tree.predict(msg_test)\n",
    "predictions_adaboost = pipeline_adaboost.predict(msg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.22      0.23      0.23       128\n",
      "     neutral       0.67      0.63      0.65       497\n",
      "    positive       0.53      0.58      0.55       252\n",
      "\n",
      "    accuracy                           0.56       877\n",
      "   macro avg       0.47      0.48      0.48       877\n",
      "weighted avg       0.56      0.56      0.56       877\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.556442417331813"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tree\n",
    "print(classification_report(predictions_tree,label_test))\n",
    "accuracy_score(label_test, predictions_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.00      0.00      0.00         0\n",
      "     neutral       0.99      0.56      0.72       818\n",
      "    positive       0.12      0.58      0.20        59\n",
      "\n",
      "    accuracy                           0.56       877\n",
      "   macro avg       0.37      0.38      0.31       877\n",
      "weighted avg       0.93      0.56      0.68       877\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5632839224629419"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "print(classification_report(predictions_naive_bayes,label_test))\n",
    "accuracy_score(label_test, predictions_naive_bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.31      0.55      0.40        76\n",
      "     neutral       0.81      0.70      0.75       538\n",
      "    positive       0.59      0.62      0.60       263\n",
      "\n",
      "    accuracy                           0.66       877\n",
      "   macro avg       0.57      0.62      0.58       877\n",
      "weighted avg       0.70      0.66      0.68       877\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6624857468643102"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ada_boost\n",
    "print(classification_report(predictions_adaboost,label_test))\n",
    "accuracy_score(label_test, predictions_adaboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes was the only method that its accuracy plummeted after keeping the dollar signs & decimal numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ngrams method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>according to the finnish russian chamber of co...</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the swedish buyout firm has sold its remaining...</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$spy wouldnt be surprised to see a green close</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shells $70 billion bg deal meets shareholder s...</td>\n",
       "      <td>-1</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ssh communications security corp stock exchang...</td>\n",
       "      <td>-1</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4377</th>\n",
       "      <td>investments in product development stood at 6....</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4378</th>\n",
       "      <td>hsbc says unit to book $585 million charge on ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4379</th>\n",
       "      <td>rising costs have forced packaging producer hu...</td>\n",
       "      <td>-1</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4380</th>\n",
       "      <td>in the building and home improvement trade sal...</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4381</th>\n",
       "      <td>helsinki afx kci konecranes said it has won an...</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4382 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Sentiment  length\n",
       "0     according to the finnish russian chamber of co...          0     128\n",
       "1     the swedish buyout firm has sold its remaining...          0     135\n",
       "2        $spy wouldnt be surprised to see a green close          1      47\n",
       "3     shells $70 billion bg deal meets shareholder s...         -1      56\n",
       "4     ssh communications security corp stock exchang...         -1     190\n",
       "...                                                 ...        ...     ...\n",
       "4377  investments in product development stood at 6....          0      72\n",
       "4378  hsbc says unit to book $585 million charge on ...         -1      56\n",
       "4379  rising costs have forced packaging producer hu...         -1     107\n",
       "4380  in the building and home improvement trade sal...          0      88\n",
       "4381  helsinki afx kci konecranes said it has won an...          1     145\n",
       "\n",
       "[4382 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = dirty_df.copy(deep=True)\n",
    "df['Sentence'] = df['Sentence'].apply(clean_sentence)\n",
    "df[\"Sentiment\"] = df['Sentiment'].map({'negative': -1, 'neutral': 0, 'positive': 1})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create ngrams from the size of n down to size 1 into a list for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'd', 'a b', 'b c', 'c d', 'a b c', 'b c d']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_ngrams(s, n):\n",
    "    words = s.split()\n",
    "    ngrams = []\n",
    "    for i in range(n):\n",
    "        to_zip = []\n",
    "        for j in range(i + 1):\n",
    "            start = j\n",
    "            end = (-i + j)\n",
    "\n",
    "            if start == 0 and end == 0:\n",
    "                ngrams.append(words)\n",
    "            elif start == 0:\n",
    "                to_zip.append(words[:end])\n",
    "            elif end == 0:\n",
    "                to_zip.append(words[start:])\n",
    "            else:\n",
    "                to_zip.append(words[start:end])\n",
    "        if i > 0:\n",
    "            ngrams.append([' '.join(x) for x in list(zip(*to_zip))])\n",
    "        \n",
    "    return sum(ngrams, [])\n",
    "\n",
    "create_ngrams('a b c d', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>length</th>\n",
       "      <th>ngrams</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>according to the finnish russian chamber of co...</td>\n",
       "      <td>0</td>\n",
       "      <td>128</td>\n",
       "      <td>[according, to, the, finnish, russian, chamber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the swedish buyout firm has sold its remaining...</td>\n",
       "      <td>0</td>\n",
       "      <td>135</td>\n",
       "      <td>[the, swedish, buyout, firm, has, sold, its, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>$spy wouldnt be surprised to see a green close</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>[$spy, wouldnt, be, surprised, to, see, a, gre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>shells $70 billion bg deal meets shareholder s...</td>\n",
       "      <td>-1</td>\n",
       "      <td>56</td>\n",
       "      <td>[shells, $70, billion, bg, deal, meets, shareh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ssh communications security corp stock exchang...</td>\n",
       "      <td>-1</td>\n",
       "      <td>190</td>\n",
       "      <td>[ssh, communications, security, corp, stock, e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Sentence  Sentiment  length  \\\n",
       "0  according to the finnish russian chamber of co...          0     128   \n",
       "1  the swedish buyout firm has sold its remaining...          0     135   \n",
       "2     $spy wouldnt be surprised to see a green close          1      47   \n",
       "3  shells $70 billion bg deal meets shareholder s...         -1      56   \n",
       "4  ssh communications security corp stock exchang...         -1     190   \n",
       "\n",
       "                                              ngrams  \n",
       "0  [according, to, the, finnish, russian, chamber...  \n",
       "1  [the, swedish, buyout, firm, has, sold, its, r...  \n",
       "2  [$spy, wouldnt, be, surprised, to, see, a, gre...  \n",
       "3  [shells, $70, billion, bg, deal, meets, shareh...  \n",
       "4  [ssh, communications, security, corp, stock, e...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add ngrams list to the dataframe\n",
    "df['ngrams'] = df['Sentence'].apply(create_ngrams, n=3)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.ngrams, df.Sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordCount = defaultdict(int) # dictionary to put all the options for word of ngrams\n",
    "# \n",
    "for s in df.Sentence:\n",
    "    for w in create_ngrams(s, 3):\n",
    "        wordCount[w] += 1\n",
    "\n",
    "counts = [(wordCount[w], w) for w in wordCount]\n",
    "counts.sort()\n",
    "# Find popular ngrams\n",
    "counts.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [x[1] for x in counts[:1000]]\n",
    "wordId = dict(zip(words, range(len(words))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature(ng):\n",
    "    feat = [0]*len(words)\n",
    "    for w in ng:\n",
    "        if w in words:\n",
    "            feat[wordId[w]] += 1\n",
    "    feat.append(1) #offset\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_modified = [feature(ng) for ng in X_train]\n",
    "X_test_modified = [feature(ng) for ng in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularized regression\n",
    "clf = linear_model.Ridge(1.0, fit_intercept=False) # MSE + 1.0 l2\n",
    "clf.fit(X_train_modified, y_train)\n",
    "theta = clf.coef_\n",
    "preds = clf.predict(X_test_modified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordSort = list(zip(theta[:-1], words))\n",
    "wordSort.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,000 most common n-grams\n",
      "--------------------------\n",
      "\n",
      "most negative n-grams\n",
      "(-0.7105239105946056, 'down')\n",
      "(-0.6498994205468586, 'long term')\n",
      "(-0.6447199796804158, 'lower')\n",
      "(-0.6281409603768257, 'fall')\n",
      "(-0.6279235330045938, 'x')\n",
      "\n",
      "most positive n-grams\n",
      "(0.7002504509283916, 'grew')\n",
      "(0.6149706723534387, 'positive')\n",
      "(0.6067431505456121, 'rise')\n",
      "(0.5743513178695382, 'improved')\n",
      "(0.5640398192082151, 'same period of')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"1,000 most common n-grams\")\n",
    "print(\"--------------------------\")\n",
    "print()\n",
    "print(\"most negative n-grams\")\n",
    "[print(w) for w in wordSort[:5]]\n",
    "print()\n",
    "print(\"most positive n-grams\")\n",
    "[print(w) for w in wordSort[:-6:-1]]\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.35      0.23      0.28       162\n",
      "           0       0.68      0.77      0.72       578\n",
      "           1       0.66      0.61      0.63       356\n",
      "\n",
      "    accuracy                           0.64      1096\n",
      "   macro avg       0.56      0.54      0.55      1096\n",
      "weighted avg       0.62      0.64      0.63      1096\n",
      "\n",
      "Accuracy:0.6405109489051095\n"
     ]
    }
   ],
   "source": [
    "clf = linear_model.LogisticRegression()\n",
    "clf.fit(X_train_modified, y_train)\n",
    "predictions =list(clf.predict(X_test_modified)) \n",
    "print(classification_report(y_test, predictions))\n",
    "acc = classification_report(y_test, predictions,output_dict=True)['accuracy']\n",
    "print(f'Accuracy:{acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.30      0.18      0.22       162\n",
      "           0       0.68      0.83      0.75       578\n",
      "           1       0.70      0.57      0.63       356\n",
      "\n",
      "    accuracy                           0.65      1096\n",
      "   macro avg       0.56      0.53      0.53      1096\n",
      "weighted avg       0.63      0.65      0.63      1096\n",
      "\n",
      "Accuracy:0.6505474452554745\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_modified, y_train)\n",
    "predictions =list(clf.predict(X_test_modified)) \n",
    "print(classification_report(y_test, predictions))\n",
    "acc = classification_report(y_test, predictions,output_dict=True)['accuracy']\n",
    "print(f'Accuracy:{acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.56      0.28      0.38       162\n",
      "           0       0.64      0.89      0.74       578\n",
      "           1       0.74      0.44      0.56       356\n",
      "\n",
      "    accuracy                           0.65      1096\n",
      "   macro avg       0.65      0.54      0.56      1096\n",
      "weighted avg       0.66      0.65      0.63      1096\n",
      "\n",
      "Accuracy:0.6532846715328468\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier()\n",
    "clf.fit(X_train_modified, y_train)\n",
    "predictions =list(clf.predict(X_test_modified)) \n",
    "print(classification_report(y_test, predictions))\n",
    "acc = classification_report(y_test, predictions,output_dict=True)['accuracy']\n",
    "print(f'Accuracy:{acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining N-grams and Bag of Words models\n",
    "We are going to concatinate the n-gram model and the bag of words model together. We have the features from n-gram at the beginning of DataFrame and followed of the features of Bag of Words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = [] # add number of appereances of the word based on the index\n",
    "for sentence in X_train:\n",
    "    result = [0] * 5225 # total number of unique words that appear more than once\n",
    "    for word in sentence:\n",
    "        if word in word_index:\n",
    "            result[word_index[word]] += 1\n",
    "    word_count.append(result + [len(sentence)])\n",
    "    \n",
    "word_count_2 = [] # add number of appereances of the word based on the index\n",
    "for sentence in X_test:\n",
    "    result = [0] * 5225 # total number of unique words that appear more than once\n",
    "    for word in sentence:\n",
    "        if word in word_index:\n",
    "            result[word_index[word]] += 1\n",
    "    word_count_2.append(result + [len(sentence)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_modified = pd.merge(pd.DataFrame([feature(ng) for ng in X_train]), \n",
    "                            pd.DataFrame(word_count), \n",
    "                            left_index=True, \n",
    "                            right_index=True)\n",
    "\n",
    "X_test_modified = pd.merge(pd.DataFrame([feature(ng) for ng in X_test]), \n",
    "                            pd.DataFrame(word_count_2), \n",
    "                            left_index=True, \n",
    "                            right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.27      0.14      0.18       162\n",
      "           0       0.67      0.87      0.76       578\n",
      "           1       0.77      0.57      0.66       356\n",
      "\n",
      "    accuracy                           0.67      1096\n",
      "   macro avg       0.57      0.53      0.53      1096\n",
      "weighted avg       0.64      0.67      0.64      1096\n",
      "\n",
      "Accuracy:0.6651459854014599\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train_modified, y_train)\n",
    "predictions =list(clf.predict(X_test_modified)) \n",
    "print(classification_report(y_test, predictions))\n",
    "acc = classification_report(y_test, predictions,output_dict=True)['accuracy']\n",
    "print(f'Accuracy:{acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.56      0.28      0.38       162\n",
      "           0       0.65      0.89      0.75       578\n",
      "           1       0.76      0.47      0.58       356\n",
      "\n",
      "    accuracy                           0.67      1096\n",
      "   macro avg       0.66      0.55      0.57      1096\n",
      "weighted avg       0.67      0.67      0.64      1096\n",
      "\n",
      "Accuracy:0.6651459854014599\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier()\n",
    "clf.fit(X_train_modified, y_train)\n",
    "predictions =list(clf.predict(X_test_modified)) \n",
    "print(classification_report(y_test, predictions))\n",
    "acc = classification_report(y_test, predictions,output_dict=True)['accuracy']\n",
    "print(f'Accuracy:{acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our intention was to also touch a package called TextBlob that shows the subjectivity & also polarity scores of a sentence which are also the features that we should consider to determine the sentiment of a sentence.\n",
    "https://textblob.readthedocs.io/en/dev/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting the test data\n",
    "We are going to use the Bag of Words model from the Baseline model because it produces the best prediction. Now, we use 99% of the dataset of learning and only 1% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.60      0.43      0.50         7\n",
      "     neutral       0.76      0.92      0.83        24\n",
      "    positive       1.00      0.77      0.87        13\n",
      "\n",
      "    accuracy                           0.80        44\n",
      "   macro avg       0.79      0.70      0.73        44\n",
      "weighted avg       0.80      0.80      0.79        44\n",
      "\n",
      "Accuracy: 0.7954545454545454\n"
     ]
    }
   ],
   "source": [
    "words = defaultdict(int) # counting appearance of each word\n",
    "for i in cleaned[\"Sentence_cleaned\"]:\n",
    "    for i in i.split():\n",
    "        words[i] += 1\n",
    "        \n",
    "word_index = {} # find index of a word for feature engineering\n",
    "counter = 0\n",
    "for i in words:\n",
    "    if words[i] > 1:\n",
    "        word_index[i] = counter\n",
    "        counter += 1\n",
    "word_index[\" \"] = counter\n",
    "\n",
    "word_count = [] # add number of appereances of the word based on the index\n",
    "for sentence in cleaned[\"Sentence_cleaned\"]:\n",
    "    result = [0] * 5225 # total number of unique words that appear more than once\n",
    "    for word in sentence.split(\" \"):\n",
    "        if word in word_index:\n",
    "            result[word_index[word]] += 1\n",
    "    word_count.append(result)\n",
    "\n",
    "df = pd.DataFrame(word_count)\n",
    "df[\"length\"] = cleaned[\"Sentence_cleaned\"].str.split().apply(len) # length as additional feature\n",
    "df.head()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df,cleaned[\"Sentiment\"],test_size=0.01,random_state=69)\n",
    "\n",
    "clf = AdaBoostClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "predictions =list(clf.predict(X_test)) \n",
    "print(classification_report(y_test, predictions))\n",
    "# classification_report(y_test, predictions,output_dict=True)['accuracy']\n",
    "acc = classification_report(y_test, predictions,output_dict=True)['accuracy']\n",
    "print(f'Accuracy: {acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>5216</th>\n",
       "      <th>5217</th>\n",
       "      <th>5218</th>\n",
       "      <th>5219</th>\n",
       "      <th>5220</th>\n",
       "      <th>5221</th>\n",
       "      <th>5222</th>\n",
       "      <th>5223</th>\n",
       "      <th>5224</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 5226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1  2  3  4  5  6  7  8  9  ...  5216  5217  5218  5219  5220  5221  \\\n",
       "0  1  1  1  1  1  1  1  1  2  1  ...     0     0     0     0     0     0   \n",
       "1  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "2  0  0  0  1  0  1  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "3  0  0  0  0  0  0  0  0  0  0  ...     0     0     0     0     0     0   \n",
       "4  0  0  0  0  0  0  0  1  2  0  ...     0     0     0     0     0     0   \n",
       "\n",
       "   5222  5223  5224  length  \n",
       "0     0     0     0      14  \n",
       "1     0     0     0      23  \n",
       "2     0     0     0      36  \n",
       "3     0     0     0      19  \n",
       "4     0     0     0      20  \n",
       "\n",
       "[5 rows x 5226 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"advanced_testset.csv\")\n",
    "df[\"Sentence_cleaned\"] = df[\"Sentence\"].str.lower()\n",
    "\n",
    "words = defaultdict(int) # counting appearance of each word\n",
    "for i in df[\"Sentence_cleaned\"]:\n",
    "    for i in i.split():\n",
    "        words[i] += 1\n",
    "        \n",
    "word_index = {} # find index of a word for feature engineering\n",
    "counter = 0\n",
    "for i in words:\n",
    "    if words[i] > 1:\n",
    "        word_index[i] = counter\n",
    "        counter += 1\n",
    "word_index[\" \"] = counter\n",
    "\n",
    "word_count = [] # add number of appereances of the word based on the index\n",
    "for sentence in df[\"Sentence_cleaned\"]:\n",
    "    result = [0] * 5225 # total number of unique words that appear more than once\n",
    "    for word in sentence.split(\" \"):\n",
    "        if word in word_index:\n",
    "            result[word_index[word]] += 1\n",
    "    word_count.append(result)\n",
    "\n",
    "engineered = pd.DataFrame(word_count)\n",
    "engineered[\"length\"] = df[\"Sentence_cleaned\"].str.split().apply(len) # length as additional feature\n",
    "engineered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions =list(clf.predict(engineered)) \n",
    "\n",
    "df = df.drop(\"Sentence_cleaned\", axis = 1)\n",
    "df[\"Sentiment\"] = predictions\n",
    "\n",
    "df.to_csv(\"predicted.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
